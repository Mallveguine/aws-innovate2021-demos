{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Demo: ModelParallel training with Amazon SageMaker***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker --upgrade -q\n",
    "# !pip install ipywidgets -q\n",
    "# !wget https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/advanced_functionality/tensorflow_bring_your_own/utils/generate_cifar10_tfrecords.py\n",
    "# !python generate_cifar10_tfrecords.py --data-dir cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import essentials packages, start a sagemaker session and specify the bucket name you created in the pre-requsites section of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_name    = sagemaker_session.default_bucket()\n",
    "jobs_folder    = 'jobs'\n",
    "dataset_folder = 'datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload dataset if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-453691756499/datasets/cifar10-dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets = sagemaker_session.upload_data(path='cifar10', key_prefix=f'{dataset_folder}/cifar10-dataset')\n",
    "# datasets\n",
    "\n",
    "#If dataset already exists\n",
    "datasets = f's3://{bucket_name}/{dataset_folder}/cifar10-dataset'\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 1\n",
    "\n",
    "distribution={\n",
    "              \"smdistributed\": {\n",
    "                  \"modelparallel\": {\n",
    "                      \"enabled\":True,\n",
    "                      \"parameters\": {\n",
    "                          \"microbatches\": 2, \n",
    "                          \"partitions\": 2, \n",
    "                          \"pipeline\": \"interleaved\", \n",
    "                          \"optimize\": \"speed\",\n",
    "                      }\n",
    "                  }\n",
    "              },\n",
    "               \"mpi\": {\n",
    "                   \"enabled\" : True,\n",
    "                   \"processes_per_host\" : 2,\n",
    "                   \"custom_mpi_options\" : \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "               }\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Specify hyperparameters, instance type and number of instances to distribute training to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type_name = f'{instance_type.replace(\".\",\"-\")}'\n",
    "job_name   = f'tf-modelparallel-{instance_type_name}-{time.strftime(\"%Y-%m-%d-%H-%M-%S-%j\", time.gmtime())}'\n",
    "output_path = f's3://{bucket_name}/{jobs_folder}'\n",
    "\n",
    "metric_definitions = [{'Name': 'Validation Accuracy', 'Regex': 'Validation Accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "hyperparameters = {'epochs': 50, \n",
    "                   'learning-rate': 0.01,\n",
    "                   'momentum': 0.95,\n",
    "                   'weight-decay': 2e-4,\n",
    "                   'optimizer': 'adam',\n",
    "                   'batch-size' : 256,\n",
    "                   'model-type': 'custom'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "smdp_estimator = TensorFlow(entry_point         = 'cifar10-tf2-smmodelparallel.py', \n",
    "                           source_dir           = 'code',\n",
    "                           output_path          = output_path + '/',\n",
    "                           code_location        = output_path,\n",
    "                           role                 = role,\n",
    "                           instance_count       = instance_count,\n",
    "                           instance_type        = instance_type,\n",
    "                           framework_version    = '2.3.1', \n",
    "                           py_version           = 'py37',\n",
    "                           metric_definitions   = metric_definitions,\n",
    "                           hyperparameters      = hyperparameters,\n",
    "                           distribution         = distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Specify dataset locations in Amazon S3 and then call the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-29 21:05:09 Starting - Starting the training job...\n",
      "2021-01-29 21:05:33 Starting - Launching requested ML instancesProfilerReport-1611954309: InProgress\n",
      ".........\n",
      "2021-01-29 21:06:54 Starting - Preparing the instances for training......\n",
      "2021-01-29 21:08:00 Downloading - Downloading input data...\n",
      "2021-01-29 21:08:36 Training - Downloading the training image............\n",
      "2021-01-29 21:10:39 Training - Training image download completed. Training in progress..\u001b[34m2021-01-29 21:10:40.460460: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:40.464975: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:40.642757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:40.724051: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:43,635 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:44,022 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (7.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.18.5)\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:45,808 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:45,809 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:45,816 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:45,816 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:2'] process_per_hosts: 2 num_processes: 2\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:45,818 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-01-29 21:10:45,904 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 2,\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": false,\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 \",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model-type\": \"custom\",\n",
      "        \"momentum\": 0.95,\n",
      "        \"batch-size\": 256,\n",
      "        \"learning-rate\": 0.01,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"weight-decay\": 0.0002,\n",
      "        \"epochs\": 50,\n",
      "        \"mp_parameters\": {\n",
      "            \"microbatches\": 2,\n",
      "            \"partitions\": 2,\n",
      "            \"pipeline\": \"interleaved\",\n",
      "            \"optimize\": \"speed\"\n",
      "        }\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-modelparallel-ml-p3-16xlarge-2021-01-29-21-05-09-029\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-453691756499/jobs/tf-modelparallel-ml-p3-16xlarge-2021-01-29-21-05-09-029/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10-tf2-smmodelparallel\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10-tf2-smmodelparallel.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":256,\"epochs\":50,\"learning-rate\":0.01,\"model-type\":\"custom\",\"model_dir\":\"/opt/ml/model\",\"momentum\":0.95,\"mp_parameters\":{\"microbatches\":2,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\"},\"optimizer\":\"adam\",\"weight-decay\":0.0002}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10-tf2-smmodelparallel.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose -x orte_base_help_aggregate=0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":2}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10-tf2-smmodelparallel\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-453691756499/jobs/tf-modelparallel-ml-p3-16xlarge-2021-01-29-21-05-09-029/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose -x orte_base_help_aggregate=0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":2},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":50,\"learning-rate\":0.01,\"model-type\":\"custom\",\"model_dir\":\"/opt/ml/model\",\"momentum\":0.95,\"mp_parameters\":{\"microbatches\":2,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\"},\"optimizer\":\"adam\",\"weight-decay\":0.0002},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-modelparallel-ml-p3-16xlarge-2021-01-29-21-05-09-029\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-453691756499/jobs/tf-modelparallel-ml-p3-16xlarge-2021-01-29-21-05-09-029/source/sourcedir.tar.gz\",\"module_name\":\"cifar10-tf2-smmodelparallel\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10-tf2-smmodelparallel.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--epochs\",\"50\",\"--learning-rate\",\"0.01\",\"--model-type\",\"custom\",\"--model_dir\",\"/opt/ml/model\",\"--momentum\",\"0.95\",\"--mp_parameters\",\"microbatches=2,optimize=speed,partitions=2,pipeline=interleaved\",\"--optimizer\",\"adam\",\"--weight-decay\",\"0.0002\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL-TYPE=custom\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.95\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adam\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT-DECAY=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_HP_MP_PARAMETERS={\"microbatches\":2,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\"}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:2 -np 2 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.7/site-packages/gethostname.cpython-37m-x86_64-linux-gnu.so -verbose -x orte_base_help_aggregate=0 -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVAL -x SM_CHANNEL_VALIDATION -x SM_CHANNEL_TRAIN -x SM_HP_MODEL-TYPE -x SM_HP_MOMENTUM -x SM_HP_BATCH-SIZE -x SM_HP_LEARNING-RATE -x SM_HP_OPTIMIZER -x SM_HP_MODEL_DIR -x SM_HP_WEIGHT-DECAY -x SM_HP_EPOCHS -x SM_HP_MP_PARAMETERS -x PYTHONPATH /usr/local/bin/python3.7 -m mpi4py cifar10-tf2-smmodelparallel.py --batch-size 256 --epochs 50 --learning-rate 0.01 --model-type custom --model_dir /opt/ml/model --momentum 0.95 --mp_parameters microbatches=2,optimize=speed,partitions=2,pipeline=interleaved --optimizer adam --weight-decay 0.0002\n",
      "\n",
      "\n",
      " Data for JOB [35693,1] offset 0 Total slots allocated 2\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-0-242-246#011Num slots: 2#011Max slots: 0#011Num procs: 2\n",
      " #011Process OMPI jobid: [35693,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [35693,1] App: 0 Process rank: 1 Bound: N/A\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-29 21:10:48.489 algo-1:155 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-01-29 21:10:48.489 algo-1:156 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-29 21:10:48.556 algo-1:155 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-01-29 21:10:48.556 algo-1:156 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-29 21:10:58.814: I smdistributed/modelparallel/tensorflow/auto.py:356] Total variables in device 0: 20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-29 21:10:58.814: I smdistributed/modelparallel/tensorflow/auto.py:356] Total variables in device 1: 20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-29 21:10:58.814: I smdistributed/modelparallel/tensorflow/auto.py:360] Total ops in device 0: 81\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-29 21:10:58.814: I smdistributed/modelparallel/tensorflow/auto.py:360] Total ops in device 1: 79\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 1, Epoch duration: 0.01661515235900879 sec, Training loss: 2.506680727005005, Training accuracy: 10.168769836425781\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 1, Epoch duration: 0.017040252685546875 sec, Training loss: 2.4104197025299072, Training accuracy: 12.212039947509766\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 2, Epoch duration: 0.017535924911499023 sec, Training loss: 2.8412790298461914, Training accuracy: 10.123697280883789\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 2, Epoch duration: 0.01755523681640625 sec, Training loss: 2.0708553791046143, Training accuracy: 18.239181518554688\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 3, Epoch duration: 0.017836332321166992 sec, Training loss: 3.1907851696014404, Training accuracy: 10.191306114196777\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 3, Epoch duration: 0.017020702362060547 sec, Training loss: 1.9802353382110596, Training accuracy: 20.653045654296875\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 4, Epoch duration: 0.016080856323242188 sec, Training loss: 3.4497809410095215, Training accuracy: 10.001001358032227\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 4, Epoch duration: 0.01632094383239746 sec, Training loss: 1.877824068069458, Training accuracy: 25.69361114501953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 5, Epoch duration: 0.016637086868286133 sec, Training loss: 3.749748468399048, Training accuracy: 10.303985595703125\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 5, Epoch duration: 0.01677250862121582 sec, Training loss: 1.7414591312408447, Training accuracy: 33.0128173828125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 6, Epoch duration: 0.015859127044677734 sec, Training loss: 4.2701897621154785, Training accuracy: 10.203826904296875\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 6, Epoch duration: 0.015955448150634766 sec, Training loss: 1.5774821043014526, Training accuracy: 40.76522445678711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 7, Epoch duration: 0.01717996597290039 sec, Training loss: 4.6599836349487305, Training accuracy: 10.258914947509766\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 7, Epoch duration: 0.016829729080200195 sec, Training loss: 1.425915002822876, Training accuracy: 47.87159729003906\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 8, Epoch duration: 0.01690506935119629 sec, Training loss: 4.997374534606934, Training accuracy: 10.13371467590332\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 8, Epoch duration: 0.017702102661132812 sec, Training loss: 1.2952830791473389, Training accuracy: 54.22175598144531\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 9, Epoch duration: 0.016719818115234375 sec, Training loss: 5.264183044433594, Training accuracy: 10.256410598754883\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 9, Epoch duration: 0.016472578048706055 sec, Training loss: 1.1917552947998047, Training accuracy: 58.62379837036133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 10, Epoch duration: 0.01713871955871582 sec, Training loss: 5.46206521987915, Training accuracy: 10.346553802490234\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 10, Epoch duration: 0.01732325553894043 sec, Training loss: 1.1210553646087646, Training accuracy: 61.2454948425293\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 11, Epoch duration: 0.015571832656860352 sec, Training loss: 5.59813117980957, Training accuracy: 11.060195922851562\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 11, Epoch duration: 0.015909433364868164 sec, Training loss: 1.056347131729126, Training accuracy: 63.777042388916016\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 12, Epoch duration: 0.016057968139648438 sec, Training loss: 5.89020299911499, Training accuracy: 10.30899429321289\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 12, Epoch duration: 0.016425609588623047 sec, Training loss: 1.0041837692260742, Training accuracy: 65.87289428710938\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 13, Epoch duration: 0.016575336456298828 sec, Training loss: 5.96813440322876, Training accuracy: 10.103666305541992\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 13, Epoch duration: 0.016778945922851562 sec, Training loss: 0.971837043762207, Training accuracy: 67.11488342285156\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 14, Epoch duration: 0.01647353172302246 sec, Training loss: 6.016272068023682, Training accuracy: 11.568510055541992\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 14, Epoch duration: 0.01665806770324707 sec, Training loss: 0.9327523708343506, Training accuracy: 68.53715515136719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 15, Epoch duration: 0.01648092269897461 sec, Training loss: 6.24606990814209, Training accuracy: 10.286458969116211\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 15, Epoch duration: 0.016921043395996094 sec, Training loss: 0.8990699648857117, Training accuracy: 69.65895080566406\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 16, Epoch duration: 0.016838788986206055 sec, Training loss: 6.45520544052124, Training accuracy: 9.970952987670898\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 16, Epoch duration: 0.016855478286743164 sec, Training loss: 0.8751884698867798, Training accuracy: 70.68559265136719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 17, Epoch duration: 0.0159609317779541 sec, Training loss: 6.558058261871338, Training accuracy: 10.762219429016113\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 17, Epoch duration: 0.015725135803222656 sec, Training loss: 0.841167151927948, Training accuracy: 71.63961791992188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 18, Epoch duration: 0.01707768440246582 sec, Training loss: 6.611215591430664, Training accuracy: 10.028545379638672\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 18, Epoch duration: 0.01739978790283203 sec, Training loss: 0.8179821968078613, Training accuracy: 72.75640869140625\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 19, Epoch duration: 0.016353845596313477 sec, Training loss: 6.728814601898193, Training accuracy: 9.958433151245117\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 19, Epoch duration: 0.016489028930664062 sec, Training loss: 0.8003336191177368, Training accuracy: 73.447509765625\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 20, Epoch duration: 0.016364097595214844 sec, Training loss: 6.849944114685059, Training accuracy: 10.78475570678711\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 20, Epoch duration: 0.015964508056640625 sec, Training loss: 0.7815580368041992, Training accuracy: 74.07601928710938\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 21, Epoch duration: 0.016534805297851562 sec, Training loss: 6.872459411621094, Training accuracy: 9.843249320983887\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 21, Epoch duration: 0.01674795150756836 sec, Training loss: 0.7638672590255737, Training accuracy: 74.49418640136719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 22, Epoch duration: 0.017785310745239258 sec, Training loss: 7.003864765167236, Training accuracy: 10.416666030883789\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 22, Epoch duration: 0.01783275604248047 sec, Training loss: 0.7439948916435242, Training accuracy: 75.30047607421875\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 23, Epoch duration: 0.016974925994873047 sec, Training loss: 7.012649059295654, Training accuracy: 10.559394836425781\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 23, Epoch duration: 0.01720404624938965 sec, Training loss: 0.7350865602493286, Training accuracy: 75.70613098144531\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 24, Epoch duration: 0.016976356506347656 sec, Training loss: 7.180994987487793, Training accuracy: 9.845752716064453\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 24, Epoch duration: 0.016390085220336914 sec, Training loss: 0.7204979062080383, Training accuracy: 76.02914428710938\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 25, Epoch duration: 0.01661539077758789 sec, Training loss: 7.128077030181885, Training accuracy: 10.777243614196777\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 25, Epoch duration: 0.016430139541625977 sec, Training loss: 0.7036706209182739, Training accuracy: 76.91556549072266\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 26, Epoch duration: 0.016419649124145508 sec, Training loss: 7.167442321777344, Training accuracy: 10.955028533935547\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 26, Epoch duration: 0.01642894744873047 sec, Training loss: 0.6921995282173157, Training accuracy: 77.08082580566406\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 27, Epoch duration: 0.016772747039794922 sec, Training loss: 7.233141899108887, Training accuracy: 10.754707336425781\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 27, Epoch duration: 0.01713275909423828 sec, Training loss: 0.6813413500785828, Training accuracy: 77.46894836425781\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 28, Epoch duration: 0.01624155044555664 sec, Training loss: 7.285057544708252, Training accuracy: 11.247997283935547\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 28, Epoch duration: 0.016244173049926758 sec, Training loss: 0.6724350452423096, Training accuracy: 77.78945922851562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 29, Epoch duration: 0.017506122589111328 sec, Training loss: 7.497672080993652, Training accuracy: 10.208833694458008\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 29, Epoch duration: 0.017231464385986328 sec, Training loss: 0.6633580923080444, Training accuracy: 77.95973205566406\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 30, Epoch duration: 0.017313718795776367 sec, Training loss: 7.474322319030762, Training accuracy: 9.923377990722656\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 30, Epoch duration: 0.016911745071411133 sec, Training loss: 0.6517587304115295, Training accuracy: 78.50811767578125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 31, Epoch duration: 0.01691460609436035 sec, Training loss: 7.406116008758545, Training accuracy: 10.972556114196777\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 31, Epoch duration: 0.017188549041748047 sec, Training loss: 0.6533523201942444, Training accuracy: 78.39793395996094\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 32, Epoch duration: 0.0164334774017334 sec, Training loss: 7.544203758239746, Training accuracy: 10.469250679016113\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 32, Epoch duration: 0.01615428924560547 sec, Training loss: 0.6383945345878601, Training accuracy: 78.79607391357422\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 33, Epoch duration: 0.017345905303955078 sec, Training loss: 7.620345115661621, Training accuracy: 10.103666305541992\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 33, Epoch duration: 0.017235755920410156 sec, Training loss: 0.6319290995597839, Training accuracy: 79.17918395996094\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 34, Epoch duration: 0.016910314559936523 sec, Training loss: 7.551918983459473, Training accuracy: 11.290565490722656\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 34, Epoch duration: 0.01701831817626953 sec, Training loss: 0.6189619898796082, Training accuracy: 79.54977416992188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 35, Epoch duration: 0.017101287841796875 sec, Training loss: 7.628327369689941, Training accuracy: 11.017627716064453\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 35, Epoch duration: 0.01680302619934082 sec, Training loss: 0.6126933693885803, Training accuracy: 79.75761413574219\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 36, Epoch duration: 0.01671147346496582 sec, Training loss: 7.850939750671387, Training accuracy: 9.84074592590332\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 36, Epoch duration: 0.016620397567749023 sec, Training loss: 0.6012396216392517, Training accuracy: 80.03305053710938\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 37, Epoch duration: 0.01668572425842285 sec, Training loss: 7.84120512008667, Training accuracy: 10.697114944458008\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 37, Epoch duration: 0.016550779342651367 sec, Training loss: 0.5963136553764343, Training accuracy: 80.43119049072266\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 38, Epoch duration: 0.017467260360717773 sec, Training loss: 7.891838073730469, Training accuracy: 9.803184509277344\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 38, Epoch duration: 0.017215728759765625 sec, Training loss: 0.5928359627723694, Training accuracy: 80.43870544433594\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 39, Epoch duration: 0.016812801361083984 sec, Training loss: 7.98036003112793, Training accuracy: 9.72305679321289\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 39, Epoch duration: 0.01649022102355957 sec, Training loss: 0.5865678191184998, Training accuracy: 80.45121765136719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 40, Epoch duration: 0.017534732818603516 sec, Training loss: 7.966440200805664, Training accuracy: 10.479267120361328\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 40, Epoch duration: 0.017339706420898438 sec, Training loss: 0.5811690092086792, Training accuracy: 80.45372009277344\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 41, Epoch duration: 0.016657590866088867 sec, Training loss: 7.955683708190918, Training accuracy: 10.789764404296875\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 41, Epoch duration: 0.01651930809020996 sec, Training loss: 0.5803803205490112, Training accuracy: 80.71914672851562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 42, Epoch duration: 0.01672816276550293 sec, Training loss: 7.85169792175293, Training accuracy: 11.505908966064453\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 42, Epoch duration: 0.016449689865112305 sec, Training loss: 0.5675253868103027, Training accuracy: 81.16987609863281\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 43, Epoch duration: 0.016095876693725586 sec, Training loss: 8.109028816223145, Training accuracy: 10.539362907409668\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 43, Epoch duration: 0.01651740074157715 sec, Training loss: 0.5560194849967957, Training accuracy: 81.58052825927734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 44, Epoch duration: 0.01719188690185547 sec, Training loss: 8.164018630981445, Training accuracy: 10.001001358032227\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 44, Epoch duration: 0.017645597457885742 sec, Training loss: 0.5552626848220825, Training accuracy: 81.54296875\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 45, Epoch duration: 0.016985416412353516 sec, Training loss: 7.990357398986816, Training accuracy: 11.348156929016113\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 45, Epoch duration: 0.016968727111816406 sec, Training loss: 0.5574906468391418, Training accuracy: 81.50289916992188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 46, Epoch duration: 0.016314268112182617 sec, Training loss: 8.115242004394531, Training accuracy: 10.243890762329102\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 46, Epoch duration: 0.016509056091308594 sec, Training loss: 0.5509914755821228, Training accuracy: 82.06880950927734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 47, Epoch duration: 0.017064809799194336 sec, Training loss: 8.098417282104492, Training accuracy: 10.734675407409668\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 47, Epoch duration: 0.016553878784179688 sec, Training loss: 0.5386823415756226, Training accuracy: 81.98117065429688\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 48, Epoch duration: 0.016557693481445312 sec, Training loss: 8.183735847473145, Training accuracy: 10.451723098754883\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 48, Epoch duration: 0.016874313354492188 sec, Training loss: 0.5436251759529114, Training accuracy: 81.91606140136719\u001b[0m\n",
      "\n",
      "2021-01-29 21:15:43 Uploading - Uploading generated training model\u001b[34m[1,0]<stdout>:Epoch: 49, Epoch duration: 0.015633106231689453 sec, Training loss: 8.136317253112793, Training accuracy: 10.704627990722656\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 49, Epoch duration: 0.015351295471191406 sec, Training loss: 0.5425500273704529, Training accuracy: 81.9686508178711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 50, Epoch duration: 0.01747751235961914 sec, Training loss: 8.113049507141113, Training accuracy: 11.348156929016113\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 50, Epoch duration: 0.01782083511352539 sec, Training loss: 0.5325043797492981, Training accuracy: 82.54707336425781\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:====== End of training ======\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:====== End of training ======\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-01-29 21:10:46.368264: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-01-29 21:10:46.368264: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-01-29 21:10:46.368451: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-01-29 21:10:46.368451: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-01-29 21:10:46.410093: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-01-29 21:10:46.410601: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-01-29 21:15:42,527 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2021-01-29 21:15:42,528 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-01-29 21:16:02 Completed - Training job completed\n",
      "ProfilerReport-1611954309: NoIssuesFound\n",
      "Training seconds: 467\n",
      "Billable seconds: 467\n"
     ]
    }
   ],
   "source": [
    "smdp_estimator.fit({'train': datasets,\n",
    "                    'validation': datasets,\n",
    "                    'eval': datasets}, \n",
    "                  job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
