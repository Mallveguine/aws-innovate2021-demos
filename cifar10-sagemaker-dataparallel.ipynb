{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Demo: Distributed training with Amazon SageMaker***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install sagemaker --upgrade -q\n",
    "# !pip install ipywidgets -q\n",
    "# !wget https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/advanced_functionality/tensorflow_bring_your_own/utils/generate_cifar10_tfrecords.py\n",
    "# !python generate_cifar10_tfrecords.py --data-dir cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import essentials packages, start a sagemaker session and specify the bucket name you created in the pre-requsites section of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_name    = sagemaker_session.default_bucket()\n",
    "jobs_folder    = 'jobs'\n",
    "dataset_folder = 'datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload dataset if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-453691756499/datasets/cifar10-dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets = sagemaker_session.upload_data(path='cifar10', key_prefix=f'{dataset_folder}/cifar10-dataset')\n",
    "# datasets\n",
    "\n",
    "#If dataset already exists\n",
    "datasets = f's3://{bucket_name}/{dataset_folder}/cifar10-dataset'\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** In this cell we create a SageMaker estimator, by providing it with all the information it needs to launch instances and execute training on those instances.\n",
    "\n",
    "We specify `distributions` to SMDataParallel.\n",
    "\n",
    "In the TensorFlow estimator call, we specify training script under `entry_point` and dependencies under `code`. SageMaker automatically copies these files into a TensorFlow container behind the scenes, and are executed on the training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 1\n",
    "\n",
    "distribution={'smdistributed':{\n",
    "                    'dataparallel':{\n",
    "                        'enabled': True\n",
    "                    }\n",
    "            }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Step 2:** Specify hyperparameters, instance type and number of instances to distribute training to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "instance_type_count_name = f'{instance_type.replace(\".\",\"-\")}-x-{str(instance_count)}'\n",
    "job_name   = f'tf-dataparallel-{instance_type_count_name}-{time.strftime(\"%Y-%m-%d-%H-%M-%S-%j\", time.gmtime())}'\n",
    "output_path = f's3://{bucket_name}/{jobs_folder}'\n",
    "\n",
    "metric_definitions = [{'Name': 'Validation Accuracy', 'Regex': 'Validation Accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "hyperparameters = {'epochs': 50, \n",
    "                   'learning-rate': 0.001,\n",
    "                   'momentum': 0.95,\n",
    "                   'weight-decay': 2e-4,\n",
    "                   'optimizer': 'adam',\n",
    "                   'batch-size' : 256,\n",
    "                   'model-type': 'custom'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "smdp_estimator = TensorFlow(entry_point         = 'cifar10-tf2-smdataparallel.py', \n",
    "                           source_dir           = 'code',\n",
    "                           output_path          = output_path + '/',\n",
    "                           code_location        = output_path,\n",
    "                           role                 = role,\n",
    "                           instance_count       = instance_count,\n",
    "                           instance_type        = instance_type,\n",
    "                           framework_version    = '2.3.1', \n",
    "                           py_version           = 'py37',\n",
    "                           metric_definitions   = metric_definitions,\n",
    "                           hyperparameters      = hyperparameters,\n",
    "                           distribution         = distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Specify dataset locations in Amazon S3 and then call the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smdp_estimator.fit({'train': datasets,\n",
    "                    'validation': datasets,\n",
    "                    'eval': datasets}, \n",
    "                  job_name=job_name, wait=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
